{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.,), (1,))\n",
    "])\n",
    "\n",
    "# load the MNIST dataset, without normalization\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# labels\n",
    "print (\"\\nLabels:\", train_dataset.classes)\n",
    "\n",
    "# digits of the images\n",
    "print (\"\\nClasses:\", train_dataset.targets)\n",
    "\n",
    "# shape of the data tensor\n",
    "print (\"\\nData shape:\", train_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images to visualize\n",
    "num_examples = 10\n",
    "\n",
    "# define a dataloader so that we can get images\n",
    "train_loader = DataLoader(train_dataset, batch_size=num_examples, shuffle=True)\n",
    "# get some images\n",
    "for data in train_loader:\n",
    "    img, label = data \n",
    "    break\n",
    "\n",
    "# print the shape of the image tensor\n",
    "print (img.shape)\n",
    "\n",
    "# label of images\n",
    "print (\"\\nLabels:\", label)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "# visualize the images \n",
    "for i in range(num_examples):\n",
    "    plt.subplot(1, num_examples, i + 1)\n",
    "    plt.imshow(img[i].numpy().reshape(28,28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# number of images to show \n",
    "num_examples = 10\n",
    "\n",
    "selected_indices = []\n",
    "# loop over labels\n",
    "for label in range(10):\n",
    "    \n",
    "    # select indices with the matching label\n",
    "    indices = torch.where(train_dataset.targets == label)[0]\n",
    "    \n",
    "    selected_indices.append(indices[0:10])\n",
    "    \n",
    "selected_indices = torch.cat(selected_indices)    \n",
    "\n",
    "# define a dataset only with images with matching label\n",
    "dataset = Subset(train_dataset, selected_indices)\n",
    "# shape of the data tensor\n",
    "print (\"\\nnumber of images in dataset:\", len(dataset))\n",
    "\n",
    "# define a dataloader for this (sub)-dataset\n",
    "data_loader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
    "    \n",
    "# get some images\n",
    "for data in data_loader:\n",
    "    img, labels = data \n",
    "    plt.figure(figsize=(4, 2))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(1, num_examples, i + 1)\n",
    "        plt.imshow(img[i].numpy().reshape(28,28), cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VESDE: \n",
    "    def __init__(self, sigma_min, sigma_max, dim=1, T=1):\n",
    "\n",
    "        self.T = T\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "    \n",
    "    def drift(self, X, t):\n",
    "        return torch.zeros_like(X)\n",
    "    \n",
    "    def diffusion(self, t):\n",
    "\n",
    "        sigma = self.sigma_min * (self.sigma_max/self.sigma_min) ** (t/self.T) \n",
    "\n",
    "        ret = sigma  * torch.sqrt(1.0 / self.T \\\n",
    "                                  * torch.tensor(2 * (math.log(self.sigma_max) - math.log(self.sigma_min))))\n",
    "        \n",
    "        return ret\n",
    "\n",
    "    def marginal_prob(self, X, t):\n",
    "        mean = X\n",
    "        std = self.sigma_min * (self.sigma_max/self.sigma_min) ** (t/self.T) \n",
    "        return mean, std \n",
    "\n",
    "    def prior(self, M):\n",
    "        return torch.randn(M * self.dim).reshape(-1, self.dim) * self.sigma_max\n",
    "    \n",
    "    # sample the SDE using Euler-Maruyama scheme\n",
    "    def forward_sampling(self, X0, N=100):\n",
    "        \n",
    "        if torch.is_tensor(X0) is False:\n",
    "            X = torch.tensor(X0).reshape(-1, self.dim)\n",
    "        else :\n",
    "            X = X0.reshape(-1, self.dim)\n",
    "                \n",
    "        traj = [X]\n",
    "        delta_t = self.T / N\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            b = torch.randn_like(X)\n",
    "\n",
    "            t = i * delta_t * torch.ones(X.shape[0]).reshape(-1, 1)\n",
    "            \n",
    "            drift = self.drift(X, t)\n",
    "\n",
    "            diffusion_coeff = self.diffusion(t)\n",
    "\n",
    "            X = X + drift * delta_t + diffusion_coeff * math.sqrt(delta_t) * b\n",
    "\n",
    "            traj.append(X)\n",
    "\n",
    "        return torch.stack(traj)\n",
    "\n",
    "    # sample the SDE using Euler-Maruyama scheme\n",
    "    def backward_sampling(self, X0, model, N=100): \n",
    "        \n",
    "        if torch.is_tensor(X0) is False:\n",
    "            X = torch.tensor(X0).reshape(-1, self.dim)\n",
    "        else :           \n",
    "            X = X0.reshape(-1, self.dim)\n",
    "        traj = [X]\n",
    "        delta_t = self.T / N\n",
    "\n",
    "        for i in range(N):\n",
    "            \n",
    "            b = torch.randn_like(X)\n",
    "\n",
    "            t = self.T - i * delta_t * torch.ones(X.shape[0]).reshape(-1, 1)\n",
    "\n",
    "            score = model(X, t)\n",
    "            \n",
    "            drift = self.drift(X, t)\n",
    "            diffusion_coeff = self.diffusion(t)\n",
    "\n",
    "            X = X + (-1.0 * drift + diffusion_coeff**2 * score) * delta_t + math.sqrt(delta_t) * diffusion_coeff * b\n",
    "\n",
    "            traj.append(X)\n",
    "\n",
    "        return torch.stack(traj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "\n",
    "sigma_min = 0.03\n",
    "sigma_max = 2\n",
    "dim = 28 * 28\n",
    "sde = VESDE(sigma_min, sigma_max, dim=dim, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some images\n",
    "for data in data_loader:\n",
    "    img, label = data \n",
    "    break\n",
    "    \n",
    "traj = sde.forward_sampling(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (traj.shape)\n",
    "\n",
    "for step in range(traj.shape[0]):\n",
    "    if step % 10 == 0 :\n",
    "        plt.figure(figsize=(4, 2))\n",
    "        for i in range(10):\n",
    "            plt.subplot(1, 10, i + 1)\n",
    "            plt.imshow(traj[step, i, :].reshape(28,28), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            if i == 0 : \n",
    "                plt.title(\"step=%d\" % step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbcbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyScore(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28+1, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.Tanh(),                      \n",
    "            nn.Linear(128, 28*28), \n",
    "       )\n",
    "        \n",
    "    # define how the output of model is computed given input x\n",
    "    def forward(self, x, t):\n",
    "        \n",
    "        state = torch.cat((x, t), dim=1)\n",
    "        output = self.net(state)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model = MyScore()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7accfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch-size\n",
    "batch_size = 20\n",
    "\n",
    "# total training epochs\n",
    "total_epochs = 10\n",
    "\n",
    "# represent the function g using a neural network\n",
    " \n",
    "# Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(total_epochs):   # for each epoch\n",
    "    \n",
    "    for idx, data in enumerate(data_loader):  # loop over all mini-batches \n",
    "        \n",
    "        img, label = data\n",
    "        \n",
    "        img = img.reshape(-1, dim)\n",
    "        \n",
    "        t = torch.rand(img.shape[0]).reshape(-1, 1) * T \n",
    "        \n",
    "        mean, std_t = sde.marginal_prob(img, t)        \n",
    "        \n",
    "        z = torch.randn_like(img)       \n",
    "       \n",
    "        xt = img + std_t * z\n",
    "        \n",
    "        score = model(xt,t) \n",
    "        \n",
    "        loss_batch = 0.5*torch.sum(score**2, dim=1, keepdim=True) \\\n",
    "                     + torch.sum(score * z, dim=1, keepdim=True) / std_t\n",
    "\n",
    "        loss = torch.mean(loss_batch * std_t**2)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        # gradient step\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx == 0:\n",
    "            # record the loss    \n",
    "            loss_list.append(loss.item())  \n",
    "            if epoch % 100 == 0:\n",
    "                print ('epoch=%d\\n   loss=%.4f' % (epoch, loss.item()))   \n",
    "                \n",
    "fig, ax = plt.subplots(1,1, figsize=(5, 4))\n",
    "\n",
    "ax.plot(loss_list)\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('loss vs epoch')             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "with torch.no_grad():\n",
    "    # generate a long trajectory \n",
    "    X = sde.prior(10)\n",
    "    \n",
    "    trajectory = sde.backward_sampling(X, model, N=100)\n",
    "\n",
    "    \n",
    "print (\"Number of states:\", trajectory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(trajectory.shape[0]):\n",
    "    if step % 10 == 0 :\n",
    "        plt.figure(figsize=(4, 2))\n",
    "        for i in range(10):\n",
    "            plt.subplot(1, 10, i + 1)\n",
    "            plt.imshow(trajectory[step, i, :].reshape(28,28), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            if i == 0 : \n",
    "                plt.title(\"step=%d\" % step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e389b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
